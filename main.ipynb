{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch_geometric as G\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric import transforms\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from shot import SHOTTransform\n",
    "from utils import PosAsX, SetTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"/scratch/local/ssd/nhat/data/\"\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "torch.manual_seed(2024)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    \n",
    "random_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomScale([0.5, 2]),\n",
    "        transforms.RandomRotate(180, 0),\n",
    "        transforms.RandomRotate(180, 1),\n",
    "        transforms.RandomRotate(180, 2),\n",
    "        transforms.RandomFlip(0),\n",
    "        transforms.RandomFlip(1),\n",
    "        transforms.RandomFlip(2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gshape_train = G.datasets.GeometricShapes(\n",
    "    root=DATA_PATH,\n",
    "    train=True,\n",
    "    transform=transforms.Compose([PosAsX(), transforms.FaceToEdge(), random_transform]),\n",
    ")\n",
    "gshape_val = G.datasets.GeometricShapes(\n",
    "    root=DATA_PATH,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([PosAsX(), transforms.FaceToEdge(), random_transform]),\n",
    ")\n",
    "gshape_train_loader = G.loader.DataLoader(\n",
    "    gshape_train, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True\n",
    ")\n",
    "gshape_val_loader = G.loader.DataLoader(\n",
    "    gshape_val, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_label_idx = 0\n",
    "qm9 = G.datasets.QM9(\n",
    "    root=DATA_PATH, transform=transforms.Compose([SetTarget(qm9_label_idx)])\n",
    ")\n",
    "qm9_train_loader = G.loader.DataLoader(\n",
    "    qm9, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=0\n",
    ")\n",
    "qm9_val_loader = G.loader.DataLoader(\n",
    "    qm9, batch_size=BATCH_SIZE, pin_memory=True, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0404,  1.0241,  0.0626],\n",
       "        [ 0.0173,  0.0125, -0.0274],\n",
       "        [ 0.9158,  1.3587, -0.0288],\n",
       "        [-0.5203,  1.3435, -0.7755]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qm9[1].pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0, skip=0):\n",
    "        super().__init__()\n",
    "        self.gconvs = torch.nn.ModuleList()\n",
    "        dims = [input_dim] + hidden_dim\n",
    "        for i in range(1, len(dims)):\n",
    "            self.gconvs.append(gnn.GCNConv(dims[i-1], dims[i]))\n",
    "        self.logit = nn.Linear(dims[-1], output_dim)\n",
    "        self.dropout = dropout\n",
    "        self.skip = skip\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        for i, l in enumerate(self.gconvs):\n",
    "            prev_x = x\n",
    "            x = l(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            \n",
    "            if self.skip != 0 and i % self.skip == 0:\n",
    "                x += prev_x\n",
    "        \n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = gnn.global_mean_pool(x, batch)\n",
    "        x = self.logit(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0, skip=0):\n",
    "        super().__init__()\n",
    "        self.gconvs = torch.nn.ModuleList()\n",
    "        dims = [input_dim] + hidden_dim\n",
    "        for i in range(1, len(dims)):\n",
    "            self.gconvs.append(gnn.GATv2Conv(dims[i-1], dims[i]))\n",
    "        self.logit = nn.Linear(dims[-1], output_dim)\n",
    "        self.dropout = dropout\n",
    "        self.skip = skip\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        for i, l in enumerate(self.gconvs):\n",
    "            prev_x = x\n",
    "            x = l(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            \n",
    "            if self.skip != 0 and i % self.skip == 0:\n",
    "                x += prev_x\n",
    "        \n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = gnn.global_mean_pool(x, batch)\n",
    "        x = self.logit(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, loader, optimizer, loss_fn, epoch, device=device):\n",
    "    avg_loss = 0\n",
    "    progbar = tqdm(loader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "    for data in progbar:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = loss_fn(out, data.y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        progbar.set_postfix({\"loss\": loss.item() / len(loader)})\n",
    "        \n",
    "    count = len(loader.dataset)\n",
    "    avg_loss /= count\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(model, loader, loss_fn, epoch, device=device):\n",
    "    model.eval()\n",
    "    avg_loss = 0\n",
    "    # correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "\n",
    "            loss = loss_fn(out, data.y)\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            # calculate accuracy\n",
    "            # pred = out.argmax(dim=1)\n",
    "            # correct += (pred == data.y).sum().item()\n",
    "            \n",
    "    count = len(loader.dataset)\n",
    "    avg_loss /= count\n",
    "    # acc = correct / count\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_fn, epochs=100, lr=0.01, device=device):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    # epoch_iter = trange(epochs, position=0)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_step(\n",
    "            model, train_loader, optimizer, loss_fn, epoch=i, device=device\n",
    "        )\n",
    "        val_loss = validate_step(model, val_loader, loss_fn, epoch=i, device=device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(\n",
    "            \"Epoch\",\n",
    "            i,\n",
    "            \"train_loss\",\n",
    "            train_loss,\n",
    "            \"val_loss\",\n",
    "            val_loss,\n",
    "        )\n",
    "\n",
    "    return model, [train_losses, val_losses, val_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.69it/s, Loss=0.00951, Val Loss=0.00936, Val Acc=0.9] \n"
     ]
    }
   ],
   "source": [
    "gcn_1 = train(\n",
    "    GCN(3, [32, 32], 40).to(device),\n",
    "    gshape_train_loader,\n",
    "    gshape_val_loader,\n",
    "    nn.CrossEntropyLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8%|▊         | 39/512 [00:03<00:40, 11.77it/s, loss=0.00202]Traceback (most recent call last):\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/queues.py\", line 250, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/connection.py\", line 427, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/connection.py\", line 384, in _send\n",
      "    n = write(self._handle, buf)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
      "    self._close()\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Epoch 0:   8%|▊         | 39/512 [00:14<00:40, 11.77it/s, loss=0.00202]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f29e5eafb00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/multiprocessing/connection.py\", line 947, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/nhat/miniconda3/envs/py11/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Epoch 0:  33%|███▎      | 169/512 [00:31<00:34, 10.01it/s, loss=0.00191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gcn_qm9_1 \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m      2\u001b[0m     GCN(\u001b[38;5;241m11\u001b[39m, [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m      3\u001b[0m     qm9_train_loader,\n\u001b[1;32m      4\u001b[0m     qm9_val_loader,\n\u001b[1;32m      5\u001b[0m     nn\u001b[38;5;241m.\u001b[39mL1Loss(),\n\u001b[1;32m      6\u001b[0m )\n",
      "Cell \u001b[0;32mIn[53], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, loss_fn, epochs, lr, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m val_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 9\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_step(\n\u001b[1;32m     10\u001b[0m         model, train_loader, optimizer, loss_fn, epoch\u001b[38;5;241m=\u001b[39mi, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate_step(model, val_loader, loss_fn, epoch\u001b[38;5;241m=\u001b[39mi, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     14\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, loader, optimizer, loss_fn, epoch, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m progbar \u001b[38;5;241m=\u001b[39m tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m progbar:\n\u001b[1;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch)\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/torch_geometric/data/dataset.py:292\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 292\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[1;32m    293\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:120\u001b[0m, in \u001b[0;36mInMemoryDataset.get\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx])\n\u001b[1;32m    112\u001b[0m data \u001b[38;5;241m=\u001b[39m separate(\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m,\n\u001b[1;32m    114\u001b[0m     batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m     decrement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    118\u001b[0m )\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list[idx] \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(data)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/copy.py:84\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     82\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__copy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m copier(x)\n\u001b[1;32m     86\u001b[0m reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py11/lib/python3.11/site-packages/torch_geometric/data/data.py:586\u001b[0m, in \u001b[0;36mData.__copy__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__copy__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    587\u001b[0m         out\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    588\u001b[0m     out\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gcn_qm9_1 = train(\n",
    "    GCN(11, [32, 32], 1).to(device),\n",
    "    qm9_train_loader,\n",
    "    qm9_val_loader,\n",
    "    nn.L1Loss(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
